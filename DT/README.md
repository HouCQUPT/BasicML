# Decision Tree Note
决策树是一种基本的分类和回归方法，决策树模型是一种树形结构。可以理解为 *if-then* 规则的集合。决策树的学习过程是从训练集中归纳出一组分类规则。从训练集的特征出发，依照某种策略选出根节点，并且根据这个特征将数据进行划分子集。对子集依上述规则进行操作。决策树有 *ID3*, *C4.5*, *CART*算法。
## 熵
>信息熵 *H(D)*

$$
H(D) = -\sum_{k=1}^{K}\frac{|C_k|}{|D|}log_2\frac{|C_k|}{|D|}
$$  

> 经验条件熵
$$
H(D|A) = \sum_{n=1}^N\frac{|D_i|}{|D|}H(D_i)
$$

> 信息增益 *information gain*
$$
g(D,A)=H(D)-H(D|A)
$$
## ID3 算法
输入：训练数据集 *D*， 阈值 *epsilon*  
输出：决策树 *T*
步骤如下：  
1. 数据集D中所有实例均属于同一类，返回类 *K*
2. 数据集D中的特征为空，返回数据集D中最多的类 *K*
3. 计算数据集D各特征的信息增益，选择信息增益最大的特征 *Ag*
4. 若 *Ag* 的信息增益小于 *epsilon*, 返回数据集中最多的类 *K*
5. 对特征 *Ag* 划分子集
6. 依次将子集实现1 ~ 5 的操作，递归实现决策树

2019-02-03 22:30